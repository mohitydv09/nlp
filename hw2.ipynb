{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import torch\n",
    "import time\n",
    "import wandb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmohitydv09\u001b[0m (\u001b[33mmohitydv09-university-of-minnesota5275\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rpmdt05/Code/Mohit/nlp/wandb/run-20240922_103824-8z06eaky</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mohitydv09-university-of-minnesota5275/first%20wandb%20trial/runs/8z06eaky' target=\"_blank\">Full Data run 1</a></strong> to <a href='https://wandb.ai/mohitydv09-university-of-minnesota5275/first%20wandb%20trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mohitydv09-university-of-minnesota5275/first%20wandb%20trial' target=\"_blank\">https://wandb.ai/mohitydv09-university-of-minnesota5275/first%20wandb%20trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mohitydv09-university-of-minnesota5275/first%20wandb%20trial/runs/8z06eaky' target=\"_blank\">https://wandb.ai/mohitydv09-university-of-minnesota5275/first%20wandb%20trial/runs/8z06eaky</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mohitydv09-university-of-minnesota5275/first%20wandb%20trial/runs/8z06eaky?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f74d2333f80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='first wandb trial', name='Full Data run 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'src', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 319071\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'src', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 56792\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'src', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 60743\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the dataset\n",
    "dataset = load_dataset(\"yaful/MAGE\")\n",
    "\n",
    "## Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased', clean_up_tokenization_spaces=True)\n",
    "\n",
    "## Apply the tokenizer to the dataset.\n",
    "dataset = dataset.map(lambda x: tokenizer(x['text'], truncation=True), batched=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Create subset of data for testing.\n",
    "# from datasets import DatasetDict\n",
    "# # Select the first 10000 samples from each dataset\n",
    "# subset_train = dataset['train'].select(range(1000))\n",
    "# subset_validation = dataset['validation'].select(range(500))\n",
    "# subset_test = dataset['test'].select(range(500))\n",
    "\n",
    "# # Combine them back into a DatasetDict\n",
    "# dataset = DatasetDict({\n",
    "#     'train': subset_train,\n",
    "#     'validation': subset_validation,\n",
    "#     'test': subset_test\n",
    "# })\n",
    "# dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create batch of data using DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "## Define Evaluation function\n",
    "accuracy = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_prediction):\n",
    "    predictions, labels = eval_prediction\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## Create the model.\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a trainer class.\n",
    "class CustomTrainer(Trainer):\n",
    "    def _inner_training_loop(\n",
    "            self,\n",
    "            batch_size = None, \n",
    "            args = None,\n",
    "            resume_from_checkpoint = None,\n",
    "            trial = None,\n",
    "            ignore_keys_for_eval = None\n",
    "    ):\n",
    "        number_of_epochs = args.num_train_epochs\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        eval_acc = []\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "        train_dataloader = self.get_train_dataloader()\n",
    "        eval_dataloader = self.get_eval_dataloader()\n",
    "\n",
    "        max_steps = len(train_dataloader) * number_of_epochs\n",
    "\n",
    "        for epoch in range(number_of_epochs):\n",
    "            train_loss_per_epoch = 0\n",
    "            train_acc_per_epoch = 0\n",
    "            with tqdm(train_dataloader, unit = 'batch') as training_epoch:\n",
    "                training_epoch.set_description(f\"Training Epoch {epoch}\")\n",
    "                for step, inputs in enumerate(training_epoch):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = inputs['labels']\n",
    "\n",
    "                    ## Forward pass\n",
    "                    self.optimizer.zero_grad()\n",
    "                    model_outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "\n",
    "                    ## Compute the loss\n",
    "                    loss = criterion(model_outputs['logits'], labels)\n",
    "                    train_loss_per_epoch += loss.item()\n",
    "\n",
    "                    wandb.log({\"Train Loss per epoch\":loss.item(), \"Step\":step, \"Epoch\":epoch})\n",
    "\n",
    "                    ## Calculate gradients\n",
    "                    loss.backward()\n",
    "                    ## Update weights\n",
    "                    self.optimizer.step()\n",
    "                    train_acc_per_epoch += (model_outputs['logits'].argmax(1) == labels).sum().item()\n",
    "            \n",
    "            wandb.log({\"Train Loss\":train_loss_per_epoch/len(train_dataloader),\n",
    "                       \"Train Accuracy\":train_acc_per_epoch/(len(train_dataloader)*batch_size),\n",
    "                       \"Epoch\":epoch})\n",
    "\n",
    "            ## Change the learning rate.\n",
    "            self.scheduler.step()\n",
    "            train_loss_per_epoch /= len(train_dataloader)\n",
    "            train_acc_per_epoch /= (len(train_dataloader) * batch_size)\n",
    "\n",
    "            eval_loss_per_epoch = 0\n",
    "            eval_acc_per_epoch = 0\n",
    "            with tqdm(eval_dataloader, unit='batch') as eval_epoch:\n",
    "                eval_epoch.set_description(f\"Evaluation Epoch {epoch}\")\n",
    "                with torch.no_grad():\n",
    "                    for step, inputs in enumerate(eval_epoch):\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = inputs['labels']\n",
    "\n",
    "                        ## Foward pass\n",
    "                        model_outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "                        \n",
    "                        ## Compute loss\n",
    "                        loss = criterion(model_outputs['logits'], labels)\n",
    "                        eval_loss_per_epoch += loss.item()\n",
    "\n",
    "                        ## Compute accuracy\n",
    "                        eval_acc_per_epoch += (model_outputs['logits'].argmax(1) == labels).sum().item()\n",
    "            \n",
    "            wandb.log({\"Eval Loss\": eval_loss_per_epoch / len(eval_dataloader), \n",
    "                       \"Eval Accuracy\": eval_acc_per_epoch / (len(eval_dataloader) * batch_size),\n",
    "                       \"Epoch\": epoch})\n",
    "            \n",
    "            eval_loss_per_epoch /= len(eval_dataloader)\n",
    "            eval_acc_per_epoch /= (len(eval_dataloader) * batch_size)\n",
    "\n",
    "            train_loss.append(train_loss_per_epoch)\n",
    "            train_acc.append(train_acc_per_epoch)\n",
    "            eval_acc.append(eval_acc_per_epoch)\n",
    "\n",
    "            print(f'\\tTrain Loss: {train_loss_per_epoch :.3f} | Train Acc: {train_acc_per_epoch*100:.2f}%')\n",
    "            print(f'\\tEval Loss: {eval_loss_per_epoch :.3f} | Eval Acc: {eval_acc_per_epoch*100:.2f}%')\n",
    "        print(f'Time: {(time.time()-start_time)/60:.3f} minutes ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args = training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "Use DistillBert and Increase batch size to 64, Think about graphs a bit.\n",
    "use the [CLS],[SEP] token in the model for classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0:   7%|▋         | 738/9971 [07:39<1:35:46,  1.61batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/mambaforge/envs/mohit-nlp/lib/python3.12/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 42\u001b[0m, in \u001b[0;36mCustomTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m## Compute the loss\u001b[39;00m\n\u001b[1;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(model_outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m], labels)\n\u001b[0;32m---> 42\u001b[0m train_loss_per_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss per epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m:loss\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep\u001b[39m\u001b[38;5;124m\"\u001b[39m:step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m:epoch})\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m## Calculate gradients\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mohit-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
